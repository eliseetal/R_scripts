---
title: "Experiment 5"
author: "Elise Kanber"
date: "29/06/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
### Summary

In this experiment, participants attempted to recognise three newly-learned voices. However, these voices had been modified. Two acoustic features of the voices, fundamental frequency (f0, perceptually correlated with pitch), and vocal tract length (perceptually related to a speaker's body size) were altered. Participants were either assigned to a longer training exposure group (where they listened to 80 speech excerpts per voice), or a shorter training exposure group (where they heard 20 unique speech excerpts per speaker). We found that listeners recognised the voices significantly better overall with more training compared to less training. However, confusion matrices constructed from the data suggested some interesting patterns in the ways that listeners were making decisions about identity. This script runs some exploratory acoustic analyses, to examine whether listeners were relying on particular acoustic cues to make decisions about identity in this challenging voice recognition task. 


Load packages: 
```{r}
# Wouldn't let me load tidyverse "no package called ggplot2" - had to type install.packages("ggplot2", type="binary")
library(tidyverse)
library(lme4) 
library(effects)
library(sjPlot)
```

Read in the data spreadsheets: 
```{r}
setwd("/Volumes/Elise/ONLINE_STUDY_2/5.data_spreadsheets")

# Main cleaned data frame containing participants' responses 
cleaned <- read.csv("final_cleaned_data_with_audio_file_names.csv")

# # f0 -- data frame containing mean f0 of each audio file 
# f0 <- read.csv("/Users/carolynmcgettigan/Documents/ONLINE_STUDY_2/5.data_spreadsheets/pitch_info_exploratory.csv")
# 
# # VTL -- data frame containing calculated VTL of each audio file 
# vtl <- read.csv("/Users/carolynmcgettigan/Documents/ONLINE_STUDY_2/5.data_spreadsheets/VTL_info_exploratory.csv")

# f0 -- data frame containing raw mean f0 of each audio file and as a z score
f0 <- read.csv("f0_z_scores.csv")

# vtl -- data frame containing raw VTL of each audio file and as a z score
vtl <- read.csv("vtl_z_scores.csv")
```

Join the data frames together: 
```{r}
data <- merge(cleaned, f0, by = "audio")
dat <- merge(data, vtl, by = "audio")


```

Select only the columns you want to keep: 
```{r}
dat <- dat %>% select(audio, Participant.Public.ID, exposure, Correct, Response, ANSWER, mod_step, label, age, Sex, Mean.Pitch..F0., fitch_vtl, f0_z, vtl_z)
```

First we need to create some new columns that code whether the participant responded Anna, Beth, and Clara (binary yes/no or 1/0 in each column)
e.g. a 1 in the "Anna_res" column would mean a participant responded Anna on that trial. 
```{r}
dat <- dat %>% 
  mutate(Anna_res = if_else(Response == "Anna", 1, 0), Beth_res = if_else(Response == "Beth", 1, 0), Clara_res = if_else(Response == "Clara", 1, 0)) 


dat$exposure <- as.factor(dat$exposure)
# dat$Anna_res <- as.factor(dat$Anna_res)
# dat$Beth_res <- as.factor(dat$Beth_res)
# dat$Clara_res<- as.factor(dat$Clara_res)
dat$Sex <- as.factor(dat$Sex)

# Filter out vtl outliers

dat <- dat %>%
  filter(vtl_z > -4.8)

```

# Set up the "Anna" voice binomial generalised linear mixed models 
```{r}

options(contrasts = c("contr.treatment","contr.poly"))

# Set the reference level to be the shorter training group (i.e. exposure = 20)
dat$exposure <- relevel(dat$exposure, ref = "20")

# Is there an effect of f0, vocal tract length, and training exposure group on the probability of making an "Anna" response in the voice identification task? 
model <- glmer(Anna_res ~ f0_z*vtl_z*exposure + Sex + (1|Participant.Public.ID) + (1|ANSWER), data = dat, family = "binomial")

output <- anova(model, type = "III") # Type III sums of squares - starts from most complex model to simplest.
output


# Summary of data, odds ratios, and visualisation: 
summary(model)
plot(allEffects(model))
tab_model(model)




# pdf(file = "/Users/carolynmcgettigan/Documents/Thesis/CHAPTER_3/Anna_exploratory.pdf",   # The directory you want to save the file in
# width = 10, # The width of the plot in inches
# height = 8) # The height of the plot in inches

  set_theme(geom.outline.color = "antiquewhite4", 
  geom.boxoutline.size = 0.5,
  geom.outline.size = 2, 
  geom.label.size = 5,
  geom.label.color = "black",
  title.color = "white", 
  title.size = 1.5, 
  axis.textcolor = "black", 
  axis.textsize = 1.2,
  axis.title.color = "black", 
  base = theme_classic(), 
  axis.title.size = 1.5, 
  legend.title.size = 1.2, 
  legend.item.size = 1.5, 
  legend.item.backcol = "white"
)

plot_model(model, type = "pred", terms = c("f0_z [all]","vtl_z [-2, -0.6, 0.4, 1, 3]","exposure"), vline.color = "white", line.size = 2) + 
             labs(y = "Probability of Anna Response", x = "f0 (z-transformed)", color = "Exposure") + 
    theme(strip.text.x = element_text(size = 18))


# dev.off()


# pdf(file = "/Users/carolynmcgettigan/Documents/ONLINE_STUDY_2/6.outputs/exploratory_graphs/Anna_exploratory.pdf",   # The directory you want to save the file in
# width = 10, # The width of the plot in inches
# height = 10) # The height of the plot in inches

# plot(allEffects(model))

# dev.off()
``` 
3-way interaction effect (exposure group x f0_z x vtl_z)
```{r}
full <- glmer(Clara_res ~ exposure*f0_z*vtl_z + Sex + (1|Participant.Public.ID) + (1|ANSWER), data = dat, family = "binomial")

reduced <- glmer(Clara_res ~ exposure*f0_z + exposure*vtl_z + f0_z*vtl_z + exposure + f0_z + vtl_z + (1|Participant.Public.ID) + (1|ANSWER), data = dat, family = "binomial")

anova(full,reduced)
summary(full)
```

# Set up the "Clara" voice binomial generalised linear mixed models 
```{r}
dat$exposure <- relevel(dat$exposure, ref = "20")

model <- glmer(Clara_res ~ f0_z*vtl_z*exposure + (1|Participant.Public.ID) + (1|ANSWER), data = dat, family = "binomial")
output <- anova(model, type = "III") # Type III sums of squares - starts from most complex model to simplest.
output

summary(model)
print(allEffects(model))
# plot(allEffects(model))
tab_model(model)


# pdf(file = "/Users/carolynmcgettigan/Documents/Thesis/CHAPTER_3/Clara_exploratory.pdf",   # The directory you want to save the file in
# width = 10, # The width of the plot in inches
# height = 8) # The height of the plot in inches

  set_theme(geom.outline.color = "antiquewhite4", 
  geom.boxoutline.size = 0.5,
  geom.outline.size = 2, 
  geom.label.size = 5,
  geom.label.color = "black",
  title.color = "white", 
  title.size = 1.5, 
  axis.textcolor = "black", 
  axis.textsize = 1.2,
  axis.title.color = "black", 
  base = theme_classic(), 
  axis.title.size = 1.5, 
  legend.title.size = 1.2, 
  legend.item.size = 1.5, 
  legend.item.backcol = "white"
)

plot_model(model, type = "pred", terms = c("f0_z [all]", "vtl_z [-2, -0.6, 0.4, 1, 3]", "exposure"), vline.color = "white", line.size = 2) + 
             labs(y = "Probability of Clara Response", x = "f0 (z-transformed)", color = "VTL (z-transformed)") + 
    theme(strip.text.x = element_text(size = 18))


# dev.off()


# pdf(file = "/Users/carolynmcgettigan/Documents/ONLINE_STUDY_2/6.outputs/exploratory_graphs/Clara_exploratory.pdf",   # The directory you want to save the file in
# width = 10, # The width of the plot in inches
# height = 10) # The height of the plot in inches
# 
# plot(allEffects(model))
# 
# dev.off()
```

# Set up the "Beth" voice binomial generalised linear mixed models 
```{r}
dat$exposure <- relevel(dat$exposure, ref = "20")
model <- glmer(Beth_res ~ vtl_z*f0_z*exposure + (1|Participant.Public.ID) + (1|ANSWER), data = dat, family = "binomial")
output <- anova(model, type = "III") # Type III sums of squares - starts from most complex model to simplest.
output

summary(model)
plot(allEffects(model))
tab_model(model)


# pdf(file = "/Users/carolynmcgettigan/Documents/Thesis/CHAPTER_3/Beth_exploratory_VTL_main_eff.pdf",   # The directory you want to save the file in
# width = 10, # The width of the plot in inches
# height = 8) # The height of the plot in inches
set_theme(
  geom.outline.color = "antiquewhite4", 
  geom.boxoutline.size = 0.5,
  geom.outline.size = 2, 
  geom.label.size = 5,
  geom.label.color = "black",
  title.color = "white", 
  title.size = 1.5, 
  axis.textcolor = "black", 
  axis.textsize = 1.2,
  axis.title.color = "black", 
  base = theme_classic(), 
  axis.title.size = 1.5, 
  legend.title.size = 1.2, 
  legend.item.size = 1.5, 
  legend.item.backcol = "white"
)

plot_model(model, type = "pred", terms = c("vtl_z [all]", "exposure"), vline.color = "white", line.size = 2) + 
             labs(y = "Probability of Beth Response", x = "VTL (z-transformed)", color = "Exposure") + 
    theme(strip.text.x = element_text(size = 18))

# dev.off()


# pdf(file = "/Users/carolynmcgettigan/Documents/ONLINE_STUDY_2/6.outputs/exploratory_graphs/Beth_exploratory.pdf",   # The directory you want to save the file in
# width = 10, # The width of the plot in inches
# height = 10) # The height of the plot in inches

plot(allEffects(model))

# dev.off()
```


### Summary of Results: 

Based on the observed confusion data from this experiment, the acoustic
properties of the lab-trained voices were examined, with a particular focus on whether there were any relationships between these properties and the ways in which listeners were categorising the vocal stimuli in the voice recognition task. Broadly, I observed that there were significant relationships between F0 and the likelihood of categorising excerpts as particular identities. 

In particular, for “Anna” responses, this was a negative relationship (i.e. as F0 increased, the likelihood of responding “Anna” decreased), whereas this was a positive relationship for “Clara” voices. The relationship between F0 and responses were consistently stronger for those that received
shorter training, compared to those that received longer training, suggesting an increased
reliance on this particular acoustic cue with less training. The relationship between apparent
vocal tract length (aVTL) and participants’ responses was less clear cut. There was a negative
relationship between aVTL and “Anna” responses, a positive relationship for “Beth” responses,
and no significant effect of aVTL on making a “Clara” response. No interactions were found between aVTL and training group.




